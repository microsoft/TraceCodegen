trainer:
  accelerator: ddp
  replace_sampler_ddp: False
  # https://github.com/PyTorchLightning/pytorch-lightning/issues/8262
  plugins: "ddp_find_unused_parameters_false"
  progress_bar_refresh_rate: 20
  log_every_n_steps: 100
  val_check_interval: 10000
data:
  batch_size: 2
  val_batch_size: 4
  # train_max_instances: 100000
  # val_max_instances: 1000
